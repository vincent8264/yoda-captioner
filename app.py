"""
Flask application for Yoda-style image captioning using HuggingFace's BLIP model.
This app allows users to upload images and receive Yoda-style captions generated by a fine-tuned BLIP model.
"""

from flask import Flask, request, render_template, jsonify
import threading
import requests
import base64
import gc
import json
import os

HF_TOKEN = os.environ.get('HF_TOKEN')
app = Flask(__name__)
app.config['MAX_CONTENT_LENGTH'] = 10 * 1024 * 1024

# HF api for image-to-text model inference
def query(image_encoded, args = {}):
    """
    Send request to HuggingFace's inference API for image-to-text generation.
    
    Args:
        image_encoded (str): Base64 encoded image string
        args (dict): Generation arguments for the model (temperature, top_k, top_p)
    
    Returns:
        dict: Model response containing generated caption or error message
    """
    headers = {
		"Accept" : "application/json",
		"Authorization": "Bearer " + HF_TOKEN,
		"Content-Type": "application/json" 
	}
    
    response = requests.post(
		"https://ahz74gvhq3nyzwbe.us-east-1.aws.endpoints.huggingface.cloud", 
		headers=headers, 
		json={
            "inputs": image_encoded,
            "generation_args": args
        }  
	).json()
    
    try:
        return response[0]
    except:
        return response

def wakeup():
    """
    Wake up the image-to-text model server by sending a test request.
    This helps reduce initial latency for the first real request.
    """
    try:
        _ = query("wake")
    except:
        pass
    return

@app.route('/')
def index():
    """
    Main page route handler. Renders the index page and starts a background
    thread to wake up the model server.
    
    Returns:
        str: Rendered HTML template for the main page
    """
    threading.Thread(target = wakeup).start()
    return render_template('index.html')

@app.route('/caption', methods=['POST'])
def caption():
    """
    Handle image caption generation requests. Processes uploaded images,
    sends them to the HuggingFace inference API, and returns Yoda-style captions.
    
    Returns:
        tuple: JSON response with caption or error message, and HTTP status code
        
    Raises:
        413: If uploaded file exceeds size limit
        500: If image encoding or model inference fails
        503: If model server is starting up
    """
    # Encode Image to base64
    try:
        file = request.files.get('image')
        image_encoded = base64.b64encode(file.read()).decode("utf-8")
    except Exception as e:
        app.logger.error(f'Image encoding error: {e}')
        return jsonify({'error': f'Image encoding error: {e}'}), 500
    
    # Get generation arguments
    settings = {}
    try:
        settings = json.loads(request.form.get('settings'))
    except: 
        pass
    
    # Model Inference with API
    response = query(image_encoded, settings)
    if 'error' in response:
        if '503' in response['error']:
            return jsonify({'error': "Server starting up, please wait for a moment"}), 503
        app.logger.error(f'Model error: {response["error"]}')
        return jsonify({'error': f'Model error: {response["error"]}'}), 500
    caption = response['generated_caption']
    
    del image_encoded
    gc.collect()
    app.logger.info('Successfully generated caption')    
    return jsonify({'caption': caption})

@app.errorhandler(413)
def request_entity_too_large(error):
    """
    Error handler for file size limit exceeded (HTTP 413).
    
    Args:
        error: The error object from Flask
    
    Returns:
        tuple: JSON response with error message and 413 status code
    """
    return jsonify({'error': 'File size exceeds backend server limits.'}), 413
 
if __name__ == '__main__':
    app.run(debug=False)